{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cb4e215-f545-43c5-9862-cc3c415c3dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca86886a-c235-4555-8d2b-7ad0a5c55a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input file name\n",
    "input_file='data.csv'\n",
    "\n",
    "# load the input dataset into a pandas dataframe\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# select only product and description column\n",
    "df = df[[\"product\", \"description\"]] \n",
    "print(f\"Number of Products: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aaea27-f9d3-4e38-bbe7-4d73e8b8ce77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0931b592-5964-409c-8d94-732c0a641d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd189ad-4463-48ac-bf51-0a23d601331e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df73a66-59b3-4072-8682-03bc9382871a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce0ab6a-cc18-4932-86e7-3dafd93d071d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f324dc-f5bb-4eb0-9588-17e1a66229cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6a23ec-2271-4e45-9d16-e27759431e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72cd06de-62b5-4ea8-83b8-e4b1c2e06b6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'qdrant_client'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# import torch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# from transformers import pipeline\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# from sentence_transformers import SentenceTransformer\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqdrant_client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QdrantClient\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqdrant_client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhttp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'qdrant_client'"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from transformers import pipeline\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a087e37-7bc5-487b-b844-3015be28b7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file='data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da132dcf-9064-4071-ae1a-9348f3b70796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Products: 27555\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Garlic Oil - Vegetarian Capsule 500 mg</td>\n",
       "      <td>This Product contains Garlic Oil that is known...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Water Bottle - Orange</td>\n",
       "      <td>Each product is microwave safe (without lid), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brass Angle Deep - Plain, No.2</td>\n",
       "      <td>A perfect gift for all occasions, be it your m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cereal Flip Lid Container/Storage Jar - Assort...</td>\n",
       "      <td>Multipurpose container with an attractive desi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Creme Soft Soap - For Hands &amp; Body</td>\n",
       "      <td>Nivea Creme Soft Soap gives your skin the best...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             product  \\\n",
       "0             Garlic Oil - Vegetarian Capsule 500 mg   \n",
       "1                              Water Bottle - Orange   \n",
       "2                     Brass Angle Deep - Plain, No.2   \n",
       "3  Cereal Flip Lid Container/Storage Jar - Assort...   \n",
       "4                 Creme Soft Soap - For Hands & Body   \n",
       "\n",
       "                                         description  \n",
       "0  This Product contains Garlic Oil that is known...  \n",
       "1  Each product is microwave safe (without lid), ...  \n",
       "2  A perfect gift for all occasions, be it your m...  \n",
       "3  Multipurpose container with an attractive desi...  \n",
       "4  Nivea Creme Soft Soap gives your skin the best...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the input dataset into a pandas dataframe\n",
    "df = pd.read_csv(input_file)\n",
    "df = df[[\"product\", \"description\"]]  # select only product and description column\n",
    "\n",
    "print(f\"Number of Products: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b36f10d-d900-4ccb-bfec-a68d618a40d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588d9948-5617-412d-a4c6-b576c086aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"query-engine-products\"\n",
    "\n",
    "collections = client.get_collections()\n",
    "print(collections)\n",
    "\n",
    "# only create collection if it doesn't exist\n",
    "if collection_name not in [c.name for c in collections.collections]:\n",
    "    client.recreate_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=models.VectorParams(    # Vector Params to be revisited\n",
    "            size=384,\n",
    "            distance=models.Distance.COSINE,\n",
    "        ),\n",
    "    )\n",
    "collections = client.get_collections()\n",
    "print(collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1f4882-a541-46e4-841b-56e7ce67efa7",
   "metadata": {},
   "source": [
    "Next, we need to initialize our retriever. The retriever will mainly do two things:\n",
    "\n",
    "- Generate embeddings for all context passages (context vectors/embeddings)\n",
    "- Generate embeddings for our questions (query vector/embedding)\n",
    "\n",
    "The retriever will generate embeddings in a way that the questions and context passages containing answers to our questions are nearby in the vector space. We can use cosine similarity to calculate the similarity between the query and context embeddings to find the context passages that contain potential answers to our question.\n",
    "\n",
    "### Embedding model\n",
    "\n",
    "We will use a SentenceTransformer model named ``multi-qa-MiniLM-L6-cos-v1`` designed for semantic search and trained on 215M (question, answer) pairs from diverse sources as our retriever. It's also quite competitive on two embedding and retrieval benchmarks: [MTEB](https://github.com/embeddings-benchmark/mteb) and [BEIR](arxiv.org/abs/2104.08663)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adb6273-5d47-4338-a52e-b4653cd9291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# load the retriever model from huggingface model hub\n",
    "retriever = SentenceTransformer(\"multi-qa-MiniLM-L6-cos-v1\", device=device)\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34420ac-a2cf-47da-894c-dc0aa24a989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512  # specify batch size according to your RAM and compute, higher batch size = more RAM usage\n",
    "\n",
    "for index in tqdm(range(0, len(df), batch_size)):\n",
    "    i_end = min(index + batch_size, len(df))  # find end of batch\n",
    "    batch = df.iloc[index:i_end]  # extract batch\n",
    "    emb = retriever.encode(batch[\"plot\"].tolist()).tolist()  # generate embeddings for batch\n",
    "    meta = batch.to_dict(orient=\"records\")  # get metadata\n",
    "    ids = list(range(index, i_end))  # create unique IDs\n",
    "\n",
    "    # upsert to qdrant\n",
    "    client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=models.Batch(ids=ids, vectors=emb, payloads=meta),\n",
    "    )\n",
    "\n",
    "collection_vector_count = client.get_collection(collection_name=collection_name).vectors_count\n",
    "print(f\"Vector count in collection: {collection_vector_count}\")\n",
    "assert collection_vector_count == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08df6bcb-30f8-4a2d-a363-fb5cf4ff4ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "\n",
    "# load the reader model into a question-answering pipeline\n",
    "reader = pipeline(\"question-answering\", model=model_name, tokenizer=model_name)\n",
    "print(reader.model, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba74a74-ced9-49f9-9fc4-4b42de8b7b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_plot(question: str, top_k: int) -> List[str]:\n",
    "    \"\"\"\n",
    "    Get the relevant plot for a given question\n",
    "\n",
    "    Args:\n",
    "        question (str): What do we want to know?\n",
    "        top_k (int): Top K results to return\n",
    "\n",
    "    Returns:\n",
    "        context (List[str]):\n",
    "    \"\"\"\n",
    "    try:\n",
    "        encoded_query = retriever.encode(question).tolist()  # generate embeddings for the question\n",
    "\n",
    "        result = client.search(\n",
    "            collection_name=collection_name,\n",
    "            query_vector=encoded_query,\n",
    "            limit=top_k,\n",
    "        )  # search qdrant collection for context passage with the answer\n",
    "\n",
    "        context = [\n",
    "            [x.payload[\"title\"], x.payload[\"plot\"]] for x in result\n",
    "        ]  # extract title and payload from result\n",
    "        return context\n",
    "\n",
    "    except Exception as e:\n",
    "        print({e})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919902ac-95ba-4065-b536-2c1de54747d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer(question: str, context: List[str]):\n",
    "    \"\"\"\n",
    "    Extract the answer from the context for a given question\n",
    "\n",
    "    Args:\n",
    "        question (str): _description_\n",
    "        context (list[str]): _description_\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for c in context:\n",
    "        # feed the reader the question and contexts to extract answers\n",
    "        answer = reader(question=question, context=c[1])\n",
    "\n",
    "        # add the context to answer dict for printing both together, we print only first 500 characters of plot\n",
    "        answer[\"title\"] = c[0]\n",
    "        results.append(answer)\n",
    "\n",
    "    # sort the result based on the score from reader model\n",
    "    sorted_result = sorted(results, key=lambda x: x[\"score\"], reverse=True)\n",
    "    for i in range(len(sorted_result)):\n",
    "        print(f\"{i+1}\", end=\" \")\n",
    "        print(\n",
    "            \"Answer: \",\n",
    "            sorted_result[i][\"answer\"],\n",
    "            \"\\n  Title: \",\n",
    "            sorted_result[i][\"title\"],\n",
    "            \"\\n  score: \",\n",
    "            sorted_result[i][\"score\"],\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
